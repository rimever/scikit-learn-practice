{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # visualization tool\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "pd.DataFrame(diabetes.data, columns=(\"age\", \"sex\", \"bmi\", \"map\", \"tc\", \"ldl\", \"hdl\", \"tch\", \"ltg\", \"glu\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_table('diabetes.tab.csv', nrows=None)\n",
    "print('diabetes_df shape:', diabetes_df.shape)\n",
    "diabetes_df = diabetes_df.rename(columns={'BP':'map','S1': 'tc','S2':'ldl','S3':'hdl','S4':'tch','S5':'ltg','S6':'glu'})\n",
    "\n",
    "diabetes_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = diabetes_df.corr()\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k  = 11\n",
    "cols = corrmat.nlargest(k, 'Y')['Y'].index\n",
    "cm = np.corrcoef(diabetes_df[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar = True, annot = True, square=True, fmt='.2f', annot_kws={'size':10},yticklabels=cols.values,xticklabels=cols.values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # visualization tool\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns=(\"age\", \"sex\", \"bmi\", \"map\", \"tc\", \"ldl\", \"hdl\", \"tch\", \"ltg\", \"glu\"))\n",
    "\n",
    "\n",
    "\n",
    "linear_regression = linear_model.LinearRegression()\n",
    "\n",
    "#説明変数を縦(1)の列と指定して削除します！\n",
    "X = diabetes_df.copy()\n",
    "\n",
    "#Yに目的変数を入れます！\n",
    "Y = diabetes.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "#左辺にモデル構築用のXY,テスト用のX,Yを用意します。\n",
    "#先ほど作成した、説明変数を第一引数に、目的変数を第二引数に置きます。\n",
    "#train_test_splitを足すことを忘れないでください！！\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X,Y)\n",
    "\n",
    "\n",
    "# 学習用とテスト用でデータを分離\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リッジ回帰アルゴリズム\n",
    "ridgereg = linear_model.Ridge()\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,Y)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "print(\"train mean_squared_error\",metrics.mean_squared_error(Y_train, ridgereg.predict(X_train)))\n",
    "print(\"score\",ridgereg.score(X_train,y_train))\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "print(\"test mean_squared_error\",metrics.mean_squared_error(Y_test, y_pred))\n",
    "mse = metrics.mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "estimator = lgb.LGBMRegressor(objective='regression_l2', learning_rate = 0.2, n_estimators = 100, boosting='gbdt',max_bin=31,min_data=1)\n",
    "\n",
    "params = {\n",
    "    'num_leaves': [x for x in range(30, 70, 10)],\n",
    "    'metric': ('l1', 'l2')\n",
    "    }\n",
    "gridsearch = GridSearchCV(estimator, params)\n",
    "\n",
    "# 変換器・推定器オブジェクト作成\n",
    "standardizer = StandardScaler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('standardize', standardizer),\n",
    "    ('pca', pca),\n",
    "    ('clf', gridsearch)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# テストデータに対して予測\n",
    "prediction = pl.predict(X_test)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"rmse\",rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
